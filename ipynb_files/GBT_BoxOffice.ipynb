{"cells":[{"cell_type":"code","source":["\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n\nfrom pyspark.ml.regression import GBTRegressor\nfrom pyspark.ml.feature import VectorIndexer\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":1},{"cell_type":"code","source":["'''sqlContext = SQLContext(sc)\nmovieschema = StructType([\\\n        StructField('Budget', DoubleType(), False),\\\n        StructField('domesticgross', DoubleType(), False),\\\n        StructField('globalgross', DoubleType(), False),\\\n        StructField('duration', DoubleType(), False),\\\n        StructField('language', IntegerType(), False),\\\n        StructField('country', IntegerType(), False),\\\n        StructField('imdb_score', DoubleType(), False),\\\n        StructField('majorgenres', IntegerType(), False),\\\n    ])\nmovieschema'''\ndf = spark.sql('select * from movieproject')\n\ndf.show(5)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df.cache()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["print \"Our dataset has %d rows.\" % df.count()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql.functions import col  \n# for indicating a column using a string in the line below\ndf = df.select([col(c).cast(\"double\").alias(c) for c in df.columns])\ndf.printSchema()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["train, test = df.randomSplit([0.7, 0.3])\nprint \"We have %d training examples and %d test examples.\" % (train.count(), test.count())"],"metadata":{"collapsed":false},"outputs":[],"execution_count":8},{"cell_type":"code","source":["display(train.select(\"budget\", \"globalgross\"))"],"metadata":{"collapsed":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler, VectorIndexer\nfeaturesCols = df.columns\nfeaturesCols.remove('globalgross')\n# This concatenates all feature columns into a single feature vector in a new column \"rawFeatures\".\nvectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n# This identifies categorical features and indexes them.\nvectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=4)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.regression import GBTRegressor\n# gbt\ngbt = GBTRegressor(labelCol=\"globalgross\")\n"],"metadata":{"collapsed":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n# gbt\nparamGrid = ParamGridBuilder()\\\n  .addGrid(gbt.maxDepth, [2, 5])\\\n  .addGrid(gbt.maxIter, [10, 100])\\\n  .build()\n# We define an evaluation metric.  This tells CrossValidator how well we are doing by comparing the true labels with predictions.\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n# Declare the CrossValidator, which runs model tuning for us.\ncv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, cv])\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":13},{"cell_type":"code","source":["pipelineModel = pipeline.fit(train)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":14},{"cell_type":"code","source":["predictions = pipelineModel.transform(test)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":15},{"cell_type":"code","source":["display(predictions.select(\"globalgross\", \"prediction\", *featuresCols))\n"],"metadata":{"collapsed":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":["rmse = evaluator.evaluate(predictions)\nprint \"RMSE on our test set: %g\" % rmse"],"metadata":{"collapsed":false},"outputs":[],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{"collapsed":true},"outputs":[],"execution_count":18}],"metadata":{"kernelspec":{"display_name":"Python 2 with Spark 2.0","language":"python","name":"python2-spark20"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"gbt","notebookId":1795362591720547},"nbformat":4,"nbformat_minor":0}
